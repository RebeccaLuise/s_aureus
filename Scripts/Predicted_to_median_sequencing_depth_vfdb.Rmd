---
title: "Virulence gene prevalences adjusted to sequencing depth to increase comparability across studies"
author: "Rebecca L. Knoll"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(glmmTMB)
library(ggplot2)
library(forcats)
library(scales)
library(ggpubr)
library(ggtext)
library(tidyverse)
library(broom)
```


```{r}
ps <- readRDS( "/Users/rebecca/Documents/Forschung/S_aureus_letter/r_analysis_s_aureus/s_aureus/Scripts/vfdb_phyloseq.rds")
```

```{r}
psmelt_vfdb<- phyloseq::psmelt(ps)

df <- psmelt_vfdb %>% 
  select(Sample, Abundance, total_reads, reads, study_id, timepoint_category, subject_id, sample_alias, OTU, Category)

which(is.na(df$subject_id))

df <- df %>% 
  mutate(rel_abund = Abundance/total_reads) %>% # here we calculate relative abundance of S. aureus in the sample across all taxonomic counts (total reads) in the sample
  rename(Total_read_count= reads) %>% # this is the complete read count of the sample
  rename(study=study_id, Timepoint=timepoint_category) %>% 
  rename(tax_reads = total_reads)

```

#Prep & counts from relative abundance ---
```{r}
df <- df %>%
  mutate(
    study = factor(study),
    Timepoint = factor(Timepoint),
    Total_read_count = as.numeric(Total_read_count),
    Abundance = as.numeric(Abundance)
  ) %>%
  filter(!is.na(Abundance), !is.na(Total_read_count), Total_read_count > 0) %>%
  rename(vfdb_count=Abundance)
```

## Calculate presence across different sequencing depth
```{r}
# Reference depth D* (use same D* for all outputs)
D_star <- median(df$Total_read_count, na.rm = TRUE)

D_star_min <- min(df$Total_read_count, na.rm = TRUE)

summary(df$Total_read_count, na.rm = TRUE)
D_star_1stQ <- 6397106
D_star_3rdQ <- 57788480
D_star_max <- max(df$Total_read_count, na.rm = TRUE)

df_std <- df %>%
  mutate(
    # calculate the rate of S aureus counts detected per sequenced read, multiply with one depth across all samples
     present_actual   = (vfdb_count  >= 1),
    adj_count_min = (vfdb_count / Total_read_count) * D_star_min,
    adj_count_min = (vfdb_count / Total_read_count) * D_star_min,
      present_min   = as.integer(adj_count_min >= 1),
adj_count_1stQ = (vfdb_count / Total_read_count) * D_star_1stQ,
      present_1stQ   = as.integer(adj_count_1stQ >= 1),
adj_count_median = (vfdb_count / Total_read_count) * D_star,
present_median   = as.integer(adj_count_median >= 1),
adj_count_3rdQ = (vfdb_count / Total_read_count) * D_star_3rdQ,
present_3rdQ   = as.integer(adj_count_3rdQ >= 1),
adj_count_max = (vfdb_count / Total_read_count) * D_star_max,
present_max   = as.integer(adj_count_max >= 1),
adj_rel   = adj_count_median / D_star )

```

```{r}
# correlation before, sig at actual sequencing depth
df_std %>% 
  ggplot(aes(x=vfdb_count, y= Total_read_count)) + 
  geom_point() + 
  theme(aspect.ratio = 1) + 
  scale_x_continuous(trans=pseudo_log_trans()) + 
  scale_y_continuous(trans=pseudo_log_trans()) + 
  stat_cor()

df_std %>% 
  ggplot(aes(x=present_actual, y= Total_read_count)) + 
  geom_point() + 
  theme(aspect.ratio = 1) + 
  scale_x_continuous(trans=pseudo_log_trans()) + 
  scale_y_continuous(trans=pseudo_log_trans()) + 
  stat_cor()

# correlation after, ns
df_std %>% 
  ggplot(aes(x=adj_count_median, y= Total_read_count)) + 
  geom_point() + 
  theme(aspect.ratio = 1) + 
  scale_x_continuous(trans=pseudo_log_trans()) + 
  scale_y_continuous(trans=pseudo_log_trans()) +
  stat_cor()

df_std %>% 
  ggplot(aes(x=present_median, y= Total_read_count)) + 
  geom_point() + 
  theme(aspect.ratio = 1) + 
  scale_x_continuous(trans=pseudo_log_trans()) + 
  scale_y_continuous(trans=pseudo_log_trans()) + 
  stat_cor()

df_std%>% 
  ggplot(aes(x=adj_count_median, y= adj_rel)) + 
  geom_point() + 
  theme(aspect.ratio = 1) + 
  #scale_x_continuous(trans=pseudo_log_trans()) + 
  #scale_y_continuous(trans=pseudo_log_trans()) +
  stat_cor()

# correlation after min, ns
df_std %>% 
  ggplot(aes(x=adj_count_min, y= Total_read_count)) + 
  geom_point() + 
  theme(aspect.ratio = 1) + 
  scale_x_continuous(trans=pseudo_log_trans()) + 
  scale_y_continuous(trans=pseudo_log_trans()) +
  stat_cor()

# correlation after 1stQ
df_std %>% 
  ggplot(aes(x=adj_count_1stQ, y= Total_read_count)) + 
  geom_point() + 
  theme(aspect.ratio = 1) + 
  scale_x_continuous(trans=pseudo_log_trans()) + 
  scale_y_continuous(trans=pseudo_log_trans()) +
  stat_cor()

df_std %>% 
  ggplot(aes(x=present_1stQ, y= Total_read_count)) + 
  geom_point() + 
  theme(aspect.ratio = 1) + 
  scale_x_continuous(trans=pseudo_log_trans()) + 
  scale_y_continuous(trans=pseudo_log_trans()) +
  stat_cor()

```

```{r}

#------------------------------------------------------------
# Prepare transformed values (avoid log(0))
df_std <- df_std %>%
  mutate(
    count_pseudo = vfdb_count,
    adj_count_pseudo = adj_count_median,
    depth_pseudo = Total_read_count
  )

# Function to fit lm on log10 scale & extract R², r, p
get_stats <- function(x, y) {
  # log-transform safely
  lx <- log10(x + 1)
  ly <- log10(y + 1)
  fit <- lm(ly ~ lx)
  smry <- summary(fit)
  r2 <- smry$r.squared
  r  <- sqrt(r2) * sign(coef(fit)[2])
  p  <- smry$coefficients[2,4]
  list(r2 = r2, r = r, p = p)
}

stats_before <- get_stats(df_std$Total_read_count, df_std$present_actual)
stats_after  <- get_stats(df_std$Total_read_count, df_std$present_median)

#------------------------------------------------------------
# Scatterplots with pseudo_log_trans
plot_scatter <- function(df, x, y, stats, title) {
  label <- paste0(
    "R² = ", round(stats$r2, 3),
    ", r = ", round(stats$r, 3),
    ", p = ", signif(stats$p, 3)
  )
  
  ggplot(df, aes(x = {{x}}, y = {{y}})) +
    geom_point(alpha = 0.6) +
    theme(aspect.ratio = 1) +
    scale_x_continuous(trans = pseudo_log_trans()) +
    scale_y_continuous(trans = pseudo_log_trans()) +
    labs(
      title = title,
      subtitle = paste("Depth reference D* =", format(D_star, big.mark=",")),
      x = "Total read count",
      y = deparse(substitute(y))
    ) +
    
    annotate("text",
             x = max(df$Total_read_count, na.rm=TRUE),
             y = min(df[[deparse(substitute(y))]], na.rm=TRUE)+1,
             label = label,
             hjust = 1, vjust = 0, size = 4, fontface = "bold", color='red')
}

p_before <- plot_scatter(df_std, Total_read_count, present_actual,
                         stats_before, "Before depth adjustment")

p_after  <- plot_scatter(df_std, Total_read_count, present_median,
                         stats_after, "After depth adjustment")

p_before
p_after
```


```{r}
df_std %>% 
  ggplot(aes(x=vfdb_count, y= adj_count_median)) + 
  geom_point() + 
  theme(aspect.ratio = 1) + 
  scale_x_log10() + 
  scale_y_log10() + 
  stat_cor()

df_std %>% 
  ggplot(aes(x=rel_abund, y= adj_rel)) + 
  geom_point() + 
  theme(aspect.ratio = 1) + 
  scale_x_log10() + 
  scale_y_log10() + 
  stat_cor()
```

```{r}
# Define short names (keys = long names, values = short labels)
short_map <- c(
  "PRIMAL"      = "PRIMAL",
   "Gibson_2016_preterm"="Gibson",
  "Rahman_2018_preterm_NICU"="Rahman",
  "Gasparrini_2019_infant"="Gasparrini",
  "Morrow_2016_preterm_infants"="Morrow",
  "Parnanen_2019_infant"="Pärnanen" 
)
```

# Mean prevalence across genes (not summed presence/absence across genes)
```{r}
# Short names (extend as needed)
# --- Define the fixed order (must match your palette keys) ---
study_order <- c("PRIMAL","Gibson","Rahman","Gasparrini","Morrow","Pärnanen")
time_levels <- c("DOL 1-8","DOL 9-42","DOL 43-455")

# Short names already built in df_std via short_map
short_map
# N per study×timepoint (for labels)
n_by_group <- df_std %>% count(study, Timepoint, name = "N")

# =========================
# A) PREVALENCE (≥1 read at D*) in fixed order (per Timepoint)
# =========================
prev_by_study_tp <- df_std %>%
  group_by(study, Timepoint) %>%
  summarise(prevalence = mean(present_median), .groups = "drop") %>%
  left_join(n_by_group, by = c("study","Timepoint")) %>%
  mutate(
    study_short = ifelse(study %in% names(short_map),
                         short_map[as.character(study)],
                         as.character(study)),
    Timepoint = factor(Timepoint, levels = time_levels),
    study_short = factor(study_short, levels = study_order),
    x_label = paste0(as.character(study_short), ", N=", N),
    x_key   = paste(Timepoint, x_label, sep = "|")
  ) %>%
  group_by(Timepoint) %>%
  arrange(study_short, .by_group = TRUE) %>%
  ungroup()

levels_prev <- prev_by_study_tp %>%
  arrange(Timepoint, study_short) %>%
  pull(x_key) %>% unique()

prev_by_study_tp <- prev_by_study_tp %>%
  mutate(x_key = factor(x_key, levels = levels_prev))

hline_data_prev <- prev_by_study_tp %>%
  group_by(Timepoint) %>%
  summarise(hline_y = mean(prevalence, na.rm = TRUE), .groups = "drop")

# =========================
# B) REL. ABUNDANCE (ppm, log) in fixed order (per Timepoint)
# =========================
df_for_plot <- df_std %>%
  left_join(n_by_group, by = c("study","Timepoint")) %>%
  mutate(
    study_short = ifelse(study %in% names(short_map),
                         short_map[as.character(study)],
                         as.character(study)),
    Timepoint = factor(Timepoint, levels = time_levels),
    study_short = factor(study_short, levels = study_order),
    x_label = paste0(as.character(study_short), ", N=", N),
    x_key   = paste(Timepoint, x_label, sep = "|")
  ) %>%
  group_by(Timepoint) %>%
  arrange(study_short, .by_group = TRUE) %>%
  ungroup()

levels_abund <- df_for_plot %>%
  arrange(Timepoint, study_short) %>%
  pull(x_key) %>% unique()

df_for_plot <- df_for_plot %>%
  mutate(x_key = factor(x_key, levels = levels_abund))

hline_data_relab <- df_for_plot %>%
  group_by(Timepoint) %>%
  summarise(hline_y = mean(adj_rel * 1e6, na.rm = TRUE), .groups = "drop")

# =========================
# Palette: map by NAME; legend order = study_order
# =========================
fill_palette <- c(
  "PRIMAL"     = "#88C9BF",
  "Gibson"     = "#D9D9D9",
  "Rahman"     = "#BDBDBD",
  "Gasparrini" = "#969696",
  "Morrow"     = "#636363",
  "Pärnanen"   = "#4D4D4D"
)
present <- union(unique(as.character(prev_by_study_tp$study_short)),
                 unique(as.character(df_for_plot$study_short)))
legend_order <- study_order[study_order %in% present]
fill_palette <- fill_palette[legend_order]

# =========================
# Plots (labels stripped from x_key)
# =========================
p_prev <- ggplot(prev_by_study_tp, aes(x = x_key, y = prevalence, fill = study_short)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = fill_palette, breaks = legend_order, drop = FALSE) +
  facet_grid(~ Timepoint, scales = "free_x", space = "free") +
  geom_hline(data = hline_data_prev, aes(yintercept = hline_y),
             colour = "black", linetype = 2, inherit.aes = FALSE) +
  scale_x_discrete(labels = function(x) sub("^[^|]*\\|", "", x)) +
  labs(
    title = "Depth-standardized virulence gene prevalence (≥1 read at D*)",
    subtitle = paste0("Simple rescaling to D* = ", format(D_star, big.mark=","), " reads"),
    y = "virulence gene prevalence", x = "", fill = "Study"
  ) +
  theme_minimal(base_size = 14) +
  theme(strip.background = element_rect(fill = "#F0F0F0", colour = "black"),
        strip.text = element_text(face = "bold", size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = ggtext::element_markdown(),
        panel.spacing = unit(1, "lines")) +
  guides(fill = guide_legend(nrow = 1, position = "bottom"))

p_rel <- ggplot(df_for_plot, aes(x = x_key, y = adj_rel * 1e6, fill = study_short)) +
  geom_boxplot(outlier.shape = NA, width = 0.6) +
  scale_y_log10() +
  scale_fill_manual(values = fill_palette, breaks = legend_order, drop = FALSE) +
  facet_grid(~ Timepoint, scales = "free_x", space = "free") +
  geom_hline(data = hline_data_relab, aes(yintercept = hline_y),
             colour = "black", linetype = 2, inherit.aes = FALSE) +
  scale_x_discrete(labels = function(x) sub("^[^|]*\\|", "", x)) +
  labs(
    title = "Depth-standardized virulence gene relative abundance at D*",
    #subtitle = paste0("Simple rescaling to D* = ", format(D_star, big.mark=","), " reads"),
    y = "virulence gene adjusted reads per million", x = "", fill = "Study"
  ) +
  theme_minimal(base_size = 14) +
  theme(strip.background = element_rect(fill = "#F0F0F0", colour = "black"),
        strip.text = element_text(face = "bold", size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = ggtext::element_markdown(),
        title= ggtext::element_markdown(),
        panel.spacing = unit(1, "lines")) +
  guides(fill = guide_legend(nrow = 1, position = "bottom"))

print(p_prev)
print(p_rel)
```

```{r}
library(dplyr)
library(ggplot2)

# before adjustment
df %>%
  mutate(detected = as.integer(vfdb_count > 0)) %>%
  group_by(study) %>%
  summarize(median_reads = median(Total_read_count, na.rm=TRUE),
            mean_detect_rate = mean(detected, na.rm=TRUE)) -> summary_by_study

ggplot(df, aes(x = Total_read_count, y = as.integer(vfdb_count>0), color = study)) +
  geom_jitter(height = 0.02, alpha = 0.4) +
  stat_smooth(method = "glm", method.args = list(family = "binomial"),
              se = FALSE, aes(group = study)) +
  scale_x_log10() +
  labs(x = "Total reads (log scale)", y = "Observed detection (0/1)",
       title = "Detection probability vs sequencing depth before depth adjustment to D*") +
  theme_minimal()

ggplot(df_std, aes(x = Total_read_count, y = as.integer(vfdb_count>0))) +
  geom_jitter(height = 0.02, alpha = 0.4) +
  stat_smooth(method = "glm", method.args = list(family = "binomial"),
              se = FALSE) +
  scale_x_log10() +
  labs(x = "Total reads (log scale)", y = "Observed detection (0/1)",
       title = "Detection probability vs sequencing depth BEFORE depth adjustment to D*") +
  theme_minimal()

# after adjustment
df_std %>%
  mutate(detected = as.integer(adj_count_median >= 1)) %>%
  group_by(study) %>%
  summarize(median_reads = median(Total_read_count, na.rm=TRUE),
            mean_detect_rate = mean(detected, na.rm=TRUE)) -> summary_by_study_adj

ggplot(df_std, aes(x = Total_read_count, y = as.integer(adj_count_median >= 1), color = study)) +
  geom_jitter(height = 0.02, alpha = 0.4) +
  stat_smooth(method = "glm", method.args = list(family = "binomial"),
              se = FALSE, aes(group = study)) +
  scale_x_log10() +
  labs(x = "Total reads (log scale)", y = "Observed detection (0/1)",
       title = "Detection probability vs sequencing depth AFTER depth adjustment to D*") +
  theme_minimal()

ggplot(df_std, aes(x = Total_read_count, y = as.integer(adj_count_median >= 1))) +
  geom_jitter(height = 0.02, alpha = 0.4) +
  stat_smooth(method = "glm", method.args = list(family = "binomial"),
              se = FALSE) +
  scale_x_log10() +
  labs(x = "Total reads (log scale)", y = "Observed detection (0/1)",
       title = "Detection probability vs sequencing depth AFTER depth adjustment to D*") +
  theme_minimal()

# minimum sequencing depth
ggplot(df_std, aes(x = Total_read_count, y = as.integer(adj_count_min >= 1))) +
  geom_jitter(height = 0.02, alpha = 0.4) +
  stat_smooth(method = "glm", method.args = list(family = "binomial"),
              se = FALSE) +
  scale_x_log10() +
  labs(x = "Total reads (log scale)", y = "Observed detection (0/1)",
       title = "Detection probability vs sequencing depth AFTER depth adjustment to D*") +
  theme_minimal()

# 1stQ sequencing depth
ggplot(df_std, aes(x = Total_read_count, y = as.integer(adj_count_1stQ >= 1))) +
  geom_jitter(height = 0.02, alpha = 0.4) +
  stat_smooth(method = "glm", method.args = list(family = "binomial"),
              se = FALSE) +
  scale_x_log10() +
  labs(x = "Total reads (log scale)", y = "Observed detection (0/1)",
       title = "Detection probability vs sequencing depth AFTER depth adjustment to D*") +
  theme_minimal()

```
```{r}
# Fit logistic regression
fit <- glm(I(vfdb_count > 0) ~ log10(Total_read_count), 
           data = df, family = "binomial")

# Extract coefficient for log10(Total_read_count)
coef_est <- coef(summary(fit))["log10(Total_read_count)", "Estimate"]
coef_se  <- coef(summary(fit))["log10(Total_read_count)", "Std. Error"]
p_val    <- coef(summary(fit))["log10(Total_read_count)", "Pr(>|z|)"]

# Odds ratio and 95% CI
OR  <- exp(coef_est)
CI  <- exp(c(coef_est - 1.96*coef_se, coef_est + 1.96*coef_se))

# Format label
label_text <- paste0("OR = ", round(OR, 2),
                     " (", round(CI[1], 2), "-", round(CI[2], 2), ")\n",
                     "p = ", signif(p_val, 3))
ggplot(df, aes(x = log10(Total_read_count), 
               y = as.integer(vfdb_count> 0))) +
  geom_jitter(height = 0.02, alpha = 0.4) +
  stat_smooth(method = "glm", 
              method.args = list(family = "binomial"), 
              se = FALSE, color = "blue") +
  labs(x = "log10(Total reads)", y = "virus genes detected unadjusted (0/1)") +
  annotate("text", x = 5, y = 0.9,   # adjust position as needed
           label = label_text,
           hjust = 0, size = 4)
```
```{r}
# Fit logistic regression
fit <- glm(I(present_median >= 1) ~ log10(Total_read_count), 
           data = df_std, family = "binomial")

# Extract coefficient for log10(Total_read_count)
coef_est <- coef(summary(fit))["log10(Total_read_count)", "Estimate"]
coef_se  <- coef(summary(fit))["log10(Total_read_count)", "Std. Error"]
p_val    <- coef(summary(fit))["log10(Total_read_count)", "Pr(>|z|)"]

# Odds ratio and 95% CI
OR  <- exp(coef_est)
CI  <- exp(c(coef_est - 1.96*coef_se, coef_est + 1.96*coef_se))

# Format label
label_text <- paste0("OR = ", round(OR, 2),
                     " (", round(CI[1], 2), "-", round(CI[2], 2), ")\n",
                     "p = ", signif(p_val, 3))
ggplot(df_std, aes(x = log10(Total_read_count), 
               y = as.integer(present_median >= 1))) +
  geom_jitter(height = 0.02, alpha = 0.4) +
  stat_smooth(method = "glm", 
              method.args = list(family = "binomial"), 
              se = FALSE, color = "blue") +
  labs(x = "log10(Total reads)", y = "virus genes detected adjusted To D* (0/1)") +
  annotate("text", x = 5, y = 0.9,   # adjust position as needed
           label = label_text,
           hjust = 0, size = 4)
```

# calculate to minimum reads
```{r}
prev_by_study_tp_min <- df_std %>%
  group_by(study, Timepoint) %>%
  summarise(prevalence = mean(present_min), .groups = "drop") %>%
  left_join(n_by_group, by = c("study","Timepoint")) %>%
  mutate(
    study_short = ifelse(study %in% names(short_map),
                         short_map[as.character(study)],
                         as.character(study)),
    Timepoint = factor(Timepoint, levels = time_levels),
    study_short = factor(study_short, levels = study_order),
    x_label = paste0(as.character(study_short), ", N=", N),
    x_key   = paste(Timepoint, x_label, sep = "|")
  ) %>%
  group_by(Timepoint) %>%
  arrange(study_short, .by_group = TRUE) %>%
  ungroup()

levels_prev_min <- prev_by_study_tp_min %>%
  arrange(Timepoint, study_short) %>%
  pull(x_key) %>% unique()

prev_by_study_tp_min <- prev_by_study_tp_min %>%
  mutate(x_key = factor(x_key, levels = levels_prev))

hline_data_prev_min <- prev_by_study_tp_min %>%
  group_by(Timepoint) %>%
  summarise(hline_y = mean(prevalence, na.rm = TRUE), .groups = "drop")

present <- union(unique(as.character(prev_by_study_tp_min$study_short)),
                 unique(as.character(df_for_plot$study_short)))
legend_order <- study_order[study_order %in% present]
fill_palette <- fill_palette[legend_order]

# =========================
# Plots (labels stripped from x_key)
# =========================
 ggplot(prev_by_study_tp_min, aes(x = x_key, y = prevalence, fill = study_short)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = fill_palette, breaks = legend_order, drop = FALSE) +
  facet_grid(~ Timepoint, scales = "free_x", space = "free") +
  geom_hline(data = hline_data_prev, aes(yintercept = hline_y),
             colour = "black", linetype = 2, inherit.aes = FALSE) +
  scale_x_discrete(labels = function(x) sub("^[^|]*\\|", "", x)) +
  labs(
    title = "Depth-standardized virulence prevalence (≥1 read at D* min)",
    subtitle = paste0("Simple rescaling to D* = ", format(D_star_min, big.mark=","), " reads"),
    y = "*S. aureus* prevalence", x = "", fill = "Study"
  ) +
  theme_minimal(base_size = 14) +
  theme(strip.background = element_rect(fill = "#F0F0F0", colour = "black"),
        strip.text = element_text(face = "bold", size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = ggtext::element_markdown(),
        panel.spacing = unit(1, "lines")) +
  guides(fill = guide_legend(nrow = 1, position = "bottom"))


```


Prevalence estimates at shallow sequencing depths underestimate biological prevalence due to reduced detection sensitivity, but the consistency across adjusted depths increases confidence that our findings are robust

# Prevalence of any virulence gene per study/timepoint
```{r}

# ---- 1) Which presence columns do you have? ----
presence_cols <- c("present_actual", "present_min", "present_1stQ",
                   "present_median", "present_3rdQ", "present_max")

# ---- 2) Helper to coerce presence-like columns to 0/1/NA ----
to_bin <- function(x) {
  # returns integer vector: 1 = present, 0 = absent, NA = missing
  if (is.logical(x)) {
    return(ifelse(is.na(x), NA_integer_, as.integer(x)))
  }
  if (is.numeric(x)) {
    return(ifelse(is.na(x), NA_integer_, as.integer(x)))
  }
  # character-ish
  x_up <- toupper(as.character(x))
  dplyr::case_when(
    x_up %in% c("TRUE","T","1")  ~ 1L,
    x_up %in% c("FALSE","F","0") ~ 0L,
    TRUE                         ~ NA_integer_
  )
}

# ---- 3) Make a cleaned dataframe with binary presence cols ----
df_clean <- df_std %>%
  mutate(across(all_of(presence_cols), to_bin))

# ---- 4) Per-sample collapse: "any gene present (TRUE/FALSE/NA)" per depth ----
#    NA means: this sample had no non-missing gene rows for that depth
per_sample_any <- df_clean %>%
  group_by(sample_alias, study, Timepoint) %>%
  summarise(
    any_actual  = ifelse(sum(!is.na(present_actual)) == 0, NA, sum(present_actual == 1, na.rm = TRUE) >= 1),
    any_min     = ifelse(sum(!is.na(present_min)) == 0,    NA, sum(present_min == 1, na.rm = TRUE) >= 1),
    any_1stQ    = ifelse(sum(!is.na(present_1stQ)) == 0, NA, sum(present_1stQ == 1, na.rm = TRUE) >= 1),
    any_median  = ifelse(sum(!is.na(present_median)) == 0, NA, sum(present_median == 1, na.rm = TRUE) >= 1),
    any_3rdQ    = ifelse(sum(!is.na(present_3rdQ)) == 0, NA, sum(present_3rdQ == 1, na.rm = TRUE) >= 1),
    any_max     = ifelse(sum(!is.na(present_max)) == 0, NA, sum(present_max == 1, na.rm = TRUE) >= 1),
    .groups = "drop"
  )

per_sample_any <- per_sample_any %>% 
   mutate(
    study_short = ifelse(study %in% names(short_map),
                         short_map[as.character(study)],
                         as.character(study)),
    Timepoint = factor(Timepoint, levels = time_levels),
    study_short = factor(study_short, levels = study_order)) 

n_study <- per_sample_any %>% 
    group_by(study_short, Timepoint) %>%
  summarise(
    n_total = n()) %>%                        # number of samples in that
  # helpful label for plotting on x-axis (shows denominator used)
  mutate( 
    x_label = paste0(as.character(study_short), ", N=", n_total),
    x_key   = paste(Timepoint, x_label, sep = "|")
  ) %>%
  group_by(Timepoint) %>%
  arrange(study_short, .by_group = TRUE) %>%
  ungroup()

prev_by_study_tp_any <- per_sample_any%>%
  group_by(study_short, Timepoint) %>%
  summarise(
    prev_actual = mean(any_actual, na.rm=TRUE),
    prev_min    = mean(any_min, na.rm = TRUE),
    prev_1stQ   = mean(any_1stQ, na.rm = TRUE),
    prev_median = mean(any_median, na.rm = TRUE),
    prev_3rdQ   = mean(any_3rdQ, na.rm = TRUE),
    prev_max    = mean(any_max, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  left_join(n_study, by = c("study_short","Timepoint")) 

levels_prev <- prev_by_study_tp_any %>%
  arrange(Timepoint, study_short) %>%
  pull(x_key) %>% unique()

prev_by_study_tp_any <- prev_by_study_tp_any %>%
  mutate(x_key = factor(x_key, levels = levels_prev))

hline_data_prev <- prev_by_study_tp_any %>%
  group_by(Timepoint) %>%
  summarise(hline_y = median(prev_median, na.rm = TRUE), .groups = "drop")

prev_by_study_tp_any %>% 
ggplot(aes(x = x_key, fill = study_short)) +
    # bar at median
  geom_col(aes(y = prev_median), alpha = 0.7, width = 0.6) +
  # error bar from min to max
  geom_errorbar(aes(ymin = prev_1stQ, ymax = prev_3rdQ), width = 0.2, colour = "black") +

  # Q1 and Q3 ticks
  #geom_point(aes(y = q1*100), shape = 95, size = 6, colour = "black") +
  #geom_point(aes(y = q3*100), shape = 95, size = 6, colour = "black") +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = fill_palette, breaks = legend_order, drop = FALSE) +
  facet_grid(~ Timepoint, scales = "free_x", space = "free") +
  scale_x_discrete(labels = function(x) sub("^[^|]*\\|", "", x)) +
  labs(
    title = "Depth-standardized virulence gene prevalence ",
    subtitle = "Bars show prevalence at median seq depth D* = 34.2 Mio",
    y = "Virulence gene prevalence (%)", x = "", fill = "Study"
  ) +
  theme_minimal(base_size = 14) +
  theme(strip.background = element_rect(fill = "#F0F0F0", colour = "black"),
        strip.text = element_text(face = "bold", size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = ggtext::element_markdown(),
        title = ggtext::element_markdown(),
        panel.spacing = unit(1, "lines")) +
  guides(fill = guide_legend(nrow = 1, position = "bottom"))
```


# subset to S_aureus positive samples only
here I will count S_aureus pos if at least 1 mOTU at actual sequencing depth for S.aureues was detected
```{r}
aureus_df <- readRDS("../S.aureus_only_dataframe.rds")

aureus_df <-aureus_df %>% 
  mutate(s_aureus_pos = case_when(Abundance >=1~T, T~F))

s_aureus_pos <- df_std %>% 
  left_join(aureus_df %>% select(sample_alias, s_aureus_pos), by="sample_alias") %>% 
  filter(s_aureus_pos==T)

# ---- 3) Make a cleaned dataframe with binary presence cols ----
df_clean <- s_aureus_pos %>%
  mutate(across(all_of(presence_cols), to_bin))

# ---- 4) Per-sample collapse: "any gene present (TRUE/FALSE/NA)" per depth ----
#    NA means: this sample had no non-missing gene rows for that depth
per_sample_any <- df_clean %>%
  group_by(sample_alias, study, Timepoint) %>%
  summarise(
    any_actual  = ifelse(sum(!is.na(present_actual)) == 0, NA, sum(present_actual == 1, na.rm = TRUE) >= 1),
    any_min     = ifelse(sum(!is.na(present_min)) == 0,    NA, sum(present_min == 1, na.rm = TRUE) >= 1),
    any_1stQ    = ifelse(sum(!is.na(present_1stQ)) == 0, NA, sum(present_1stQ == 1, na.rm = TRUE) >= 1),
    any_median  = ifelse(sum(!is.na(present_median)) == 0, NA, sum(present_median == 1, na.rm = TRUE) >= 1),
    any_3rdQ    = ifelse(sum(!is.na(present_3rdQ)) == 0, NA, sum(present_3rdQ == 1, na.rm = TRUE) >= 1),
    any_max     = ifelse(sum(!is.na(present_max)) == 0, NA, sum(present_max == 1, na.rm = TRUE) >= 1),
    .groups = "drop"
  )

per_sample_any <- per_sample_any %>% 
   mutate(
    study_short = ifelse(study %in% names(short_map),
                         short_map[as.character(study)],
                         as.character(study)),
    Timepoint = factor(Timepoint, levels = time_levels),
    study_short = factor(study_short, levels = study_order)) 

n_study <- per_sample_any %>% 
    group_by(study_short, Timepoint) %>%
  summarise(
    n_total = n()) %>%                        # number of samples in that
  # helpful label for plotting on x-axis (shows denominator used)
  mutate( 
    x_label = paste0(as.character(study_short), ", N=", n_total),
    x_key   = paste(Timepoint, x_label, sep = "|")
  ) %>%
  group_by(Timepoint) %>%
  arrange(study_short, .by_group = TRUE) %>%
  ungroup()

prev_by_study_tp_any <- per_sample_any%>%
  group_by(study_short, Timepoint) %>%
  summarise(
    prev_actual = mean(any_actual, na.rm=TRUE),
    prev_min    = mean(any_min, na.rm = TRUE),
    prev_1stQ   = mean(any_1stQ, na.rm = TRUE),
    prev_median = mean(any_median, na.rm = TRUE),
    prev_3rdQ   = mean(any_3rdQ, na.rm = TRUE),
    prev_max    = mean(any_max, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  left_join(n_study, by = c("study_short","Timepoint")) 

levels_prev <- prev_by_study_tp_any %>%
  arrange(Timepoint, study_short) %>%
  pull(x_key) %>% unique()

prev_by_study_tp_any <- prev_by_study_tp_any %>%
  mutate(x_key = factor(x_key, levels = levels_prev))

hline_data_prev <- prev_by_study_tp_any %>%
  group_by(Timepoint) %>%
  summarise(hline_y = median(prev_median, na.rm = TRUE), .groups = "drop")

prev_by_study_tp_any %>% 
ggplot(aes(x = x_key, fill = study_short)) +
    # bar at median
  geom_col(aes(y = prev_median), alpha = 0.7, width = 0.6) +
  # error bar from min to max
  geom_errorbar(aes(ymin = prev_1stQ, ymax = prev_3rdQ), width = 0.2, colour = "black") +

  # Q1 and Q3 ticks
  #geom_point(aes(y = q1*100), shape = 95, size = 6, colour = "black") +
  #geom_point(aes(y = q3*100), shape = 95, size = 6, colour = "black") +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_fill_manual(values = fill_palette, breaks = legend_order, drop = FALSE) +
  facet_grid(~ Timepoint, scales = "free_x", space = "free") +
  scale_x_discrete(labels = function(x) sub("^[^|]*\\|", "", x)) +
  labs(
    title = "Depth-standardized virulence gene prevalence in *S.aureus* pos. samples",
    subtitle = "Bars show prevalence at median seq depth D* = 34.2 Mio",
    y = "Virulence gene prevalence (%)", x = "", fill = "Study"
  ) +
  theme_minimal(base_size = 14) +
  theme(strip.background = element_rect(fill = "#F0F0F0", colour = "black"),
        strip.text = element_text(face = "bold", size = 14),
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.title.y = ggtext::element_markdown(),
        title = ggtext::element_markdown(),
        panel.spacing = unit(1, "lines")) +
  guides(fill = guide_legend(nrow = 1, position = "bottom"))
```




```